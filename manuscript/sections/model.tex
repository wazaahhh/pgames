\section*{Private Property Model}
Our study is carried out for the prisoner's dilemma game (PD), which is often used to model selfish behavior of individuals when cooperation is risky and defection is tempting, but where the outcome of mutual defection is inferior to cooperation on both sides \cite{axelrod1981evolution,nowak2006five}. 
Formally, the so-called reward $R$ represents the payoff for mutual cooperation, while the payoff for defection of both sides is the {\it punishment} $P$. $T$ represents the {\it temptation} to unilaterally defect, which results in the {\it sucker's payoff} $S$ for the cooperating individual. The inequalities $T > R > P > S$ and $2R > T + S$ define the classical prisoner's dilemma, in which it is more profitable to defect, no matter what strategy the other individual selects. Therefore, rationally behaving individuals would be expected to defect when they meet once. However, defection by everyone is implied as well by the game-dynamical replicator equation \cite{epstein1998zones}, which takes into account imitation of superior strategies, or payoff-driven birth-and-death processes. In contrast, a coexistence of cooperators and defectors is predicted for the snowdrift game (SD). Although it is also used to study social cooperation, its payoffs are characterized by $T > R > S > P$ (i.e., $S > P$ rather than $P > S$) \cite{}.\\

As is well-known \cite{nowak2006five}, cooperation can, for example, be supported by repeated interactions \cite{axelrod1981evolution}, by intergroup competition with or without altruistic punishment\cite{traulsen2006evolution,fehr2002altruistic,boyd2003evolution}, and by network reciprocity based on the clustering of cooperators \cite{nowak1992evolutionary,szabo2002phase,hauert2004spatial}. In the latter case, the level of cooperation in 2-dimensional spatial games is further enhanced by ``disordered environments" (10\% inaccessible empty locations) \cite{vainstein2001disordered}, and by
diffusive mobility, provided that the mobility parameter is in a suitable range \cite{vainstein2007does}. Usually, strategy mutations, random relocations, and other sources of stochasticity can significantly challenge the formation and survival of cooperative clusters \cite{}. {\it Success-driven} migration, in contrast, is a robust mechanism: By leaving unfavorable neighborhoods, seeking more favorable
ones, and remaining in cooperative neighborhoods, it supports cooperative clusters very efficiently against the destructive effects of noise, thus preventing defector invasion in a large area of payoff parameters \cite{helbing2009outbreak}.\\

The {\it private property} game implies the possibility to expel players from locations with higher pay-off, and as such, it extends the success-driven migration game by allowing migrations to any location within the migration range. We assume $N$ individuals on a two dimension square with periodic boundary conditions and $L\times L$ sites, which are either empty or occupied by one individual. Population density $d$ is a parameter with values between $0.2$ and $0.8$.\footnote{below and beyond these values, a migration game makes little sense as interactions in low density worlds may only be achievedby large migration ranges, and densities $\rightarrow 1$ almost completely remove migration opportunities.} Individuals are updated asynchronously, in a random sequential order, and each individual gets updated on average $N$ times (i.e., the number of Monte Carlo Steps $MCS = N \times L^2$). At each step, the randomly selected individual performs simultaneous interactions with the $4$ direct neighbors and compares the overall payoff with that of these neighbors. If one neighbor has a better payoff, the individual updates her strategy with the one of her best performing neighbor.\footnote{Performing the same simulations with 8 neighbors does not change the picture overall.} In absence of noise ($r=0$, equiv Fermi temperature equals to 1), this update is sure, and the individual cannot spontaneously start to cooperate ($q=0$).\\

The migration step is performed before the imitation step\cite{helbing2009outbreak}: An individual explores the expected payoffs for {\it all} sites in the Moore neighborhood $(2M + 1) \times (2M + 1)$ of range $M$. If the fictitious payoff is higher than in the current location, the individual is assumed to move to the site with the highest payoff with probability $m$ (in absence of migration noise, $m=1$). If the target site is empty, then {\it success-driven} migration occurs. On the contrary, if the site with highest payoff is already occupied by another individual, the {\it property-violation} migration occurs. With probability $s$, the focal player takes the site of the incumbent individual, who in turn is expelled to the best empty site in her own Moore neighborhood (see Figure \ref{fig:migration_diagram} for a graphical representation). With probability $1-s$ however, property violation is aborted and the individual migrates to the best empty site within the migration range. The probability $s$ encompasses the unsure nature of the property violation endeavor such as the possibility to get caught by law enforcement, or limited by some physical or technical constraints. \\
 
While small quantities of property violation introduce some amount of randomness that enhances cooperation (see Figure \ref{fig:phase_transition}a), our model is aimed at uncovering the limit conditions and the mechanisms, which help maintain or restore cooperative societies in presence of property violation. Indeed, it makes particularly sense to study limit conditions in the case of private property violation, because society want to optimize their law enforcement, hence invest the minimum for the maximum effects.\footnote{Here, we can enrich the paragraph by pulling out complex system research on transition from order to disorder (and vice-versa) when a system is optimized.}

%The resulting strategy mutations reflect deficient imitation or trial-and-error behavior. As a side effect, such noise leads to an independence of the final cooperation level from the initial one (at $t=0$), and a {\it qualitatively different} pattern formation dynamics for the same payoff values, update rules, and initial conditions ( c.f. SI Fig.1). Using the alternative Fermi update rule \cite{} would have been possible as well. However, resetting strategies rather than inverting them, combined with values $q$ much smaller than $0.5$, creates particularly adverse conditions for cooperation.\\


