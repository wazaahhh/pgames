\section*{Model}
Our study is carried out for the prisoner's dilemma game (PD), which is often used to model selfish behavior of individuals when cooperation is risky and defection is tempting, but where the outcome of mutual defection is inferior to cooperation on both sides \cite{axelrod1981evolution,nowak2006five}. Formally, the so-called reward $R$ represents the payoff for mutual cooperation, while the payoff for defection of both sides is the {\it punishment} $P$. $T$ represents the {\it temptation} to unilaterally defect, which results in the {\it sucker's payoff} $S$ for the cooperating individual. The inequalities $T > R > P > S$ and $2R > T + S$ define the classical prisoner's dilemma, in which it is more profitable to defect, no matter what strategy the other individual selects. Therefore, rationally behaving individuals would be expected to defect when they meet once. However, defection by everyone is implied as well by the game-dynamical replicator
equation \cite{epstein1998zones}, which takes into account imitation of superior strategies, or payoff-driven birth-and-death processes. In contrast, a coexistence of cooperators and defectors is predicted for the snowdrift game (SD). Although it is also used to study social cooperation, its payoffs are characterized by $T > R > S > P$ (i.e., $S > P$ rather than $P > S$).\\

As is well-known \cite{nowak2006five}, cooperation can, for example, be supported by repeated interactions \cite{axelrod1981evolution}, by intergroup competition with or without altruistic punishment\cite{traulsen2006evolution,fehr2002altruistic,boyd2003evolution}, and by network reciprocity based on the clustering of cooperators \cite{nowak1992evolutionary,szabo2002phase,hauert2004spatial}. In the latter case, the level of cooperation in 2-dimensional spatial games is further enhanced by ``disordered environments" (10\% inaccessible empty locations) \cite{vainstein2001disordered}, and by
diffusive mobility, provided that the mobility parameter is in a suitable range \cite{vainstein2007does}. Usually, strategy mutations, random relocations, and other sources of stochasticity can significantly challenge the formation and survival of cooperative clusters \cite{}. {\it Success-driven} migration, in contrast, is a robust mechanism: By leaving unfavorable neighborhoods, seeking more favorable
ones, and remaining in cooperative neighborhoods, it supports cooperative clusters very efficiently against the destructive effects of noise, thus preventing defector invasion in a large area of payoff parameters \cite{helbing2009outbreak}.\\

However, {\it success-driven} migration excludes that an individual can take the place of another individual. The {\it private property game} however is a success-driven game, which implies the possibility to expel players from locations with higher pay-off. We assume $N$ individuals on a two dimension square with periodic boundary conditions and $L\times L$ sites, which are either empty or occupied by one individual. Individuals are updated asynchronously, in a random sequential order, and each individual gets updated on average $N$ iterated (i.e., the number of Monte Carlo Steps $MCS = N \times L^2$). At each step, the randomly selected individual performs simultaneous interactions with the $4$ direct neighbors and compares the overall payoff with that of these neighbors. If one neighbor has a better payoff, the individual updates her strategy with the one of her best performing neighbor. In absence of noise ($r=0$), this update is sure, the individual cannot spontaneously start to cooperate ($q=0$).\\

The {\it success-driven migration} step is implemented as follows \cite{helbing2009outbreak}: before the imitation step, an individual explores the expected payoffs for {\it all} sites in the Moore neighborhood $(2M + 1) \times (2M + 1)$ of range $M$. If the fictitious payoff is higher than in the current location, the individual is assumed to move to the site with the highest payoff with probability $m$ (in absence of migration noise, $m=1$). If the site with highest payoff is already occupied by another individual, the {\it property-violation migration} occurs with probability $s$ this neighbor is expelled to the best empty site in her own Moore neighborhood ({\bf her strategy is not changed $\rightarrow$ check this} ). With probability $1-s$, the property violation tentative is aborted and the individual migrates to the empty site with the highest payoff. Besides property violation, which is a random variable, the individual is fully rational about her choices given information available in her Moore's neighborhood {\bf [bounded rationality $\rightarrow$ Herbert Simon]}. As such, our model encompasses the unsure nature of choices regarding property violation, such as the probability to get caught by law enforcement \cite{}, or limited by some physical \cite{} or technical constraints \cite{}. {\bf [Note that by design the private property game requires success-driven migration]}.\\

%The resulting strategy mutations reflect deficient imitation or trial-and-error behavior. As a side effect, such noise leads to an independence of the final cooperation level from the initial one (at $t=0$), and a {\it qualitatively different} pattern formation dynamics for the same payoff values, update rules, and initial conditions ( c.f. SI Fig.1). Using the alternative Fermi update rule \cite{} would have been possible as well. However, resetting strategies rather than inverting them, combined with values $q$ much smaller than $0.5$, creates particularly adverse conditions for cooperation.\\





%\subsection*{Initial configuration}
%
%\begin{enumerate}
%  \item  {\bf Grid and iterations:} Grid Size = 49x49, Moore's distance = 5, iterations = 200
%  \item {\bf Prisoners' dilemma:} $T>R>P>S$ and $2R > T+ S$, actually $T=1.3$, $R = 1$, $P=0.1$, $S=0$
%  \item {\bf empty sites:} variable
%\end{enumerate}
%
%\subsection*{execution steps}
%
%\begin{enumerate}
%\item Select a random agent on grid
%\item Play with 4 nearest neighbors and find best site
%\item with probability $m$, explore neighborhood within Moore's distance: with probability $1-s$ find best empty site, and with probability $s$ find best site (incl. both empty and occupied sites)
%\item if site with higher pay-off is found, move to this new site. If the site is occupied, expel agent to empty site with highest pay-off in expelled agent's Moore's distance.
%\item with probability $1-r$ copy best strategy form 4 nearest neighbors, and with probability $q$, spontaneously cooperate.
%\end{enumerate}


